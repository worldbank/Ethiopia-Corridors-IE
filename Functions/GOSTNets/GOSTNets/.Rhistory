if(Sys.info()[["user"]] == "robmarty") code_file_path <- "~/Documents/Github/CrashMap-Nairobi"
if(Sys.info()[["user"]] == "WB521633") root_file_path <- "C:/Users/wb521633"
if(Sys.info()[["user"]] == "robmarty") root_file_path <- "~"
#if(Sys.info()[["user"]] == "WB521633") surveycto_file_path <- "C:/Users/wb521633/Documents/Github/CrashMap-Nairobi"
if(Sys.info()[["user"]] == "robmarty") surveycto_file_path <- "~/Documents/SurveyCTO Data"
rawdata_file_path <- file.path(project_file_path, "Data", "RawData")
finaldata_file_path <- file.path(project_file_path, "Data", "FinalData")
algorithm_inputs <- file.path(project_file_path, "Data", "FinalData", "Twitter Algorithm Inputs")
tables_file_path <- file.path(project_file_path, "Papers", "Algorithm", "Tables")
figures_file_path <- file.path(project_file_path, "Papers", "Algorithm", "Figures")
outputs_file_path <- file.path(project_file_path, "Outputs")
wb_onedrive_folder <- file.path(root_file_path, "OneDrive - WBG", "smarTTrans")
# Packages ---------------------------------------------------------------------
library(leaflet)
library(jcolors)
library(googlesheets)
library(dplyr)
library(ClusterR)
library(adehabitatHR)
library(tidyr)
library(dplyr)
library(rgdal)
library(rgeos)
library(openssl)
library(data.table)
library(glmnet)
library(reshape)
library(fastDummies)
library(tidyr)
library(lubridate)
library(reshape)
library(ggplot2)
library(raster)
library(sp)
library(sf)
library(mapview)
library(tools)
library(spdep)
library(broom)
library(ggmapstyles) # devtools::install_github("dr-harper/ggmapstyles")
library(parallel)
library(pbmcapply)
library(stringr)
library(readxl)
library(doBy)
library(purrr)
library(ggmap)
library(grid)
library(gridExtra)
library(gtable)
library(scales)
library(tidyr)
library(ggpubr)
#library(wesanderson)
#library(jcolors)
library(readr)
library(htmlwidgets)
library(htmltools)
library(smoothr)
library(stringdist)
library(stringr)
library(quanteda)
library(caret)
library(bcrypt)
library(osrm)
library(parallel)
library(dplyr)
library(rdrop2)
library(readxl)
library(stringr)
library(haven)
library(readxl)
library(pbmcapply)
library(tidyr)
library(stringr)
library(ggrepel)
library(ggthemes)
library(googledrive)
library(writexl)
library(dplyr)
library(lubridate)
library(parallel)
library(pbmcapply)
library(tidyr)
library(stringr)
library(googledrive)
library(devtools)
library(pdftools)
#library(xlsx)
library(dismo)
library(stargazer)
library(MASS)
library(deldir)
library(LearnGeom)
library(lfe)
library(glmnet)
library(quanteda.classifiers) # devtools::install_github("quanteda/quanteda.svm")
#devtools::install_github("skgrange/gissr")
source(file.path(code_file_path, "Code", "Twitter Geocode Algorithm", "code", "04_algorithm", "crashmap_algorithm.R"))
source(file.path(code_file_path, "Code", "Functions and Packages", "Clustering", "cluster_crashes.R"))
source(file.path(code_file_path, "Code", "Functions and Packages", "commonly_used_functions.R"))
source("https://raw.githubusercontent.com/ramarty/fast-functions/master/R/functions_in_chunks.R")
# 1. Download Data -------------------------------------------------------------
# Downloads data from Google Sheets and appends sheets from supervisors
rodgers_sheet <- gs_title("Video Counts _Rodgers")
# Downloads data from Google Sheets and appends sheets from supervisors
rodgers_sheet <- gs_title("Video Counts _Rodgers")
andrew_sheet <- gs_title("Video Counts _Andrew")
salome_sheet <- gs_title("Video Counts _Salome")
purity_sheet <- gs_title("Video Counts _Purity")
pheliciah_sheet <- gs_title("Video Counts _Pheliciah")
road_data <- bind_rows(
rodgers_sheet %>% gs_read("Road Segment Data"),
andrew_sheet %>% gs_read("Road Segment Data"),
salome_sheet %>% gs_read("Road Segment Data"),
purity_sheet %>% gs_read("Road Segment Data"),
pheliciah_sheet %>% gs_read("Road Segment Data")
)
#### Rename variables
names(road_data) <- road_data[2,] %>% as.character()
names(road_data)
# Download Video Counts Data from Google Sheets
# NOTE: For code to work, add the Google Sheets to your Google Drive.
# 1. Download Data -------------------------------------------------------------
# Downloads data from Google Sheets and appends sheets from supervisors
rodgers_sheet <- gs_title("Video Counts _Rodgers")
andrew_sheet <- gs_title("Video Counts _Andrew")
salome_sheet <- gs_title("Video Counts _Salome")
purity_sheet <- gs_title("Video Counts _Purity")
pheliciah_sheet <- gs_title("Video Counts _Pheliciah")
road_data <- bind_rows(
rodgers_sheet %>% gs_read("Road Segment Data"),
andrew_sheet %>% gs_read("Road Segment Data"),
salome_sheet %>% gs_read("Road Segment Data"),
purity_sheet %>% gs_read("Road Segment Data"),
pheliciah_sheet %>% gs_read("Road Segment Data")
)
# 2 .Clean Dataset ----------------------------------------------------------------
#### Rename variables
names(road_data) <- road_data[2,] %>% as.character()
names(road_data)[grepl("How much traffic is there", names(road_data))] <- "Traffic Level"
names(road_data)[grepl("If someone crosses the road", names(road_data))] <- "Pedestrian Count Check"
#### Clean select variables
# Side of Road
road_data$`Side of Road Coding (A or B)` <- road_data$`Side of Road Coding (A or B)` %>% tolower %>% str_replace_all("[[:digit:]]", "")
# Video name: Some supervisors didn't include .mp4, so remove from all videos
road_data$`Video Name` <- road_data$`Video Name` %>% str_replace_all(".mp4", "")
#### Video Length: Minutes
parse_text <- function(str) eval(parse(text=str))
parse_text <- Vectorize(parse_text)
road_data$video_length_minutes <- road_data$`Video Length` %>%
str_replace_all("\\.", ":") %>%
str_replace_all(":", "+(1/60)*") %>%
parse_text %>%
as.vector()
road_data$`Video Length`
# Download Video Counts Data from Google Sheets
# NOTE: For code to work, add the Google Sheets to your Google Drive.
# 1. Download Data -------------------------------------------------------------
# Downloads data from Google Sheets and appends sheets from supervisors
rodgers_sheet <- gs_title("Video Counts _Rodgers")
andrew_sheet <- gs_title("Video Counts _Andrew")
salome_sheet <- gs_title("Video Counts _Salome")
purity_sheet <- gs_title("Video Counts _Purity")
pheliciah_sheet <- gs_title("Video Counts _Pheliciah")
road_data <- bind_rows(
rodgers_sheet %>% gs_read("Road Segment Data"),
andrew_sheet %>% gs_read("Road Segment Data"),
salome_sheet %>% gs_read("Road Segment Data"),
purity_sheet %>% gs_read("Road Segment Data"),
pheliciah_sheet %>% gs_read("Road Segment Data")
)
# 2 Rename Variables & Subset --------------------------------------------------
#### Rename variables
names(road_data) <- road_data[2,] %>% as.character()
names(road_data)[grepl("How much traffic is there", names(road_data))] <- "Traffic Level"
names(road_data)[grepl("If someone crosses the road", names(road_data))] <- "Pedestrian Count Check"
#### Remove rows without data
road_data <- road_data[!is.na(road_data$`Video Name`),]
road_data <- road_data[!(road_data$`Video Name` %in% "Video Name"),]
# 3. Clean Variables -----------------------------------------------------------
#### Clean select variables
View(road_data)
# Download Video Counts Data from Google Sheets
# NOTE: For code to work, add the Google Sheets to your Google Drive.
# 1. Download Data -------------------------------------------------------------
# Downloads data from Google Sheets and appends sheets from supervisors
rodgers_sheet <- gs_title("Video Counts _Rodgers")
andrew_sheet <- gs_title("Video Counts _Andrew")
salome_sheet <- gs_title("Video Counts _Salome")
purity_sheet <- gs_title("Video Counts _Purity")
pheliciah_sheet <- gs_title("Video Counts _Pheliciah")
road_data <- bind_rows(
rodgers_sheet %>% gs_read("Road Segment Data"),
andrew_sheet %>% gs_read("Road Segment Data"),
salome_sheet %>% gs_read("Road Segment Data"),
purity_sheet %>% gs_read("Road Segment Data"),
pheliciah_sheet %>% gs_read("Road Segment Data")
)
# 2 Rename Variables & Subset --------------------------------------------------
#### Rename variables
names(road_data) <- road_data[2,] %>% as.character()
names(road_data)[grepl("How much traffic is there", names(road_data))] <- "Traffic Level"
names(road_data)[grepl("If someone crosses the road", names(road_data))] <- "Pedestrian Count Check"
#### Remove rows without data
road_data <- road_data[!is.na(road_data$`Video Name`),]
road_data <- road_data[!(road_data$`Video Name` %in% "Video Name"),]
# 3. Clean Variables -----------------------------------------------------------
#### Clean select variables
# Side of Road
a <- road_data$`Side of Road Coding (A or B)` %>% tolower %>% str_replace_all("[[:digit:]]", "")
a
table()
table(a)
aa <- road_data$`Side of Road Coding (A or B)` %>% tolower %>% str_replace_all("[[:digit:]]", "") %>% unique()
aa
road_data$`Side of Road Coding (A or B)` %>%
tolower %>%
str_replace_all("[[:digit:]]", "")
# Download Video Counts Data from Google Sheets
# NOTE: For code to work, add the Google Sheets to your Google Drive.
# 1. Download Data -------------------------------------------------------------
# Downloads data from Google Sheets and appends sheets from supervisors
rodgers_sheet <- gs_title("Video Counts _Rodgers")
andrew_sheet <- gs_title("Video Counts _Andrew")
salome_sheet <- gs_title("Video Counts _Salome")
purity_sheet <- gs_title("Video Counts _Purity")
pheliciah_sheet <- gs_title("Video Counts _Pheliciah")
road_data <- bind_rows(
rodgers_sheet %>% gs_read("Road Segment Data"),
andrew_sheet %>% gs_read("Road Segment Data"),
salome_sheet %>% gs_read("Road Segment Data"),
purity_sheet %>% gs_read("Road Segment Data"),
pheliciah_sheet %>% gs_read("Road Segment Data")
)
# 2 Rename Variables & Subset --------------------------------------------------
#### Rename variables
names(road_data) <- road_data[2,] %>% as.character()
names(road_data)[grepl("How much traffic is there", names(road_data))] <- "Traffic Level"
names(road_data)[grepl("If someone crosses the road", names(road_data))] <- "Pedestrian Count Check"
#### Remove rows without data
road_data <- road_data[!is.na(road_data$`Video Name`),]
road_data <- road_data[!(road_data$`Video Name` %in% "Video Name"),]
# 3. Clean Variables -----------------------------------------------------------
#### Side of Road
road_data$`Side of Road Coding (A or B)` <- road_data$`Side of Road Coding (A or B)` %>%
tolower %>%
str_replace_all("[[:digit:]]", "")
#### Video name: Some supervisors didn't include .mp4, so remove from all videos
road_data$`Video Name` <- road_data$`Video Name` %>% str_replace_all(".mp4", "")
#### Video Length: Minutes
parse_text <- function(str) eval(parse(text=str))
parse_text <- Vectorize(parse_text)
road_data$video_length_minutes <- road_data$`Video Length` %>%
str_replace_all("\\.", ":") %>%
str_replace_all(":", "+(1/60)*") %>%
parse_text %>%
as.vector()
road_data$video_length_coded_minutes <- road_data$`Number of Minutes Coded of Video` %>%
str_replace_all("\\.", ":") %>%
str_replace_all(":", "+(1/60)*") %>%
parse_text %>%
as.vector()
road_data$video_length_minutes
hist(road_data$video_length_minutes)
hist(road_data$video_length_coded_minutes)
nrow(road_data)
# Download Video Counts Data from Google Sheets
# NOTE: For code to work, add the Google Sheets to your Google Drive.
# 1. Download Data -------------------------------------------------------------
# Downloads data from Google Sheets and appends sheets from supervisors
rodgers_sheet <- gs_title("Video Counts _Rodgers")
andrew_sheet <- gs_title("Video Counts _Andrew")
salome_sheet <- gs_title("Video Counts _Salome")
purity_sheet <- gs_title("Video Counts _Purity")
pheliciah_sheet <- gs_title("Video Counts _Pheliciah")
road_data <- bind_rows(
rodgers_sheet %>% gs_read("Road Segment Data"),
andrew_sheet %>% gs_read("Road Segment Data"),
salome_sheet %>% gs_read("Road Segment Data"),
purity_sheet %>% gs_read("Road Segment Data"),
pheliciah_sheet %>% gs_read("Road Segment Data")
)
# 2 Rename Variables & Subset --------------------------------------------------
#### Rename variables
names(road_data) <- road_data[2,] %>% as.character()
names(road_data)[grepl("How much traffic is there", names(road_data))] <- "Traffic Level"
names(road_data)[grepl("If someone crosses the road", names(road_data))] <- "Pedestrian Count Check"
#### Remove rows without data
road_data <- road_data[!is.na(road_data$`Video Name`),]
road_data <- road_data[!(road_data$`Video Name` %in% "Video Name"),]
# 3. Clean Variables -----------------------------------------------------------
#### Side of Road
road_data$`Side of Road Coding (A or B)` <- road_data$`Side of Road Coding (A or B)` %>%
tolower %>%
str_replace_all("[[:digit:]]", "")
#### Video name: Some supervisors didn't include .mp4, so remove from all videos
road_data$`Video Name` <- road_data$`Video Name` %>% str_replace_all(".mp4", "")
#### Video Length: Minutes
parse_text <- function(str) eval(parse(text=str))
parse_text <- Vectorize(parse_text)
road_data$video_length_minutes <- road_data$`Video Length` %>%
str_replace_all("\\.", ":") %>%
str_replace_all(":", "+(1/60)*") %>%
parse_text %>%
as.vector()
road_data$video_length_coded_minutes <- road_data$`Number of Minutes Coded of Video` %>%
str_replace_all("\\.", ":") %>%
str_replace_all(":", "+(1/60)*") %>%
parse_text %>%
as.vector()
# 5. Export --------------------------------------------------------------------
saveRDS(road_data,  file.path(rawdata_file_path, "Hotspot Survey - Video Counting", "video_counts_raw.Rds"))
write.csv(road_data, file.path(rawdata_file_path, "Hotspot Survey - Video Counting", "video_counts_raw.csv"), row.names=F)
# 1. Load Data -----------------------------------------------------------------
road_data <- readRDS(file.path(rawdata_file_path, "Hotspot Survey - Video Counting", "video_counts_raw.Rds")) %>% as.data.frame
road_data[,36] <- NULL
road_data <- road_data %>%
dplyr::rename("segment_id" = "Segment ID",
"road_side_ab" = "Side of Road Coding (A or B)",
"hotspot_id" = "Hotspot ID",
"ped_pass_walking_along_sidewalk" = "Pedestrians on PASSENGER side walking along the road using sidewalk/side of road",
"ped_pass_walking_along_road" = "Pedestrians on PASSENGER side walking along the road walking on the road",
"ped_pass_sittingstand_roadside" = "Pedestrians on PASSENER side standing/sitting on side of road (eg, vendor)",
"ped_driver_walking_along_sidewalk" = "If divided road:Pedestrians on DRIVER side walking along the road using sidewalk/side of road",
"ped_driver_walking_along_road" = "If divided road:Pedestrians on DRIVER side walking along the road walking on the road",
"ped_driver_sittingstand_roadside" = "If divided road:Pedestrians on DRIVER side standing/sitting on side of road (eg, vendor)",
"ped_crossing_sidewalk" = "Pedestrians crossing road using crosswalk",
"ped_crossing_nosidewalk" = "Pedestrians crossing road not using crosswalk (even if none nearby)",
"large_truck_count" = "Large Trucks and Vehicles",
"matatu_count" = "Matatus",
"car_count" = "Cars",
"other_motorzied_vehicle_count" = "Other Motorzied Vehicles Except Motorcycles (e.g., tuk-tuks)",
"motorcycle_count" = "Motorcycles",
"bicycle_count" = "Bicycles (Non-Motorized)",
"nonmotorized_vehicle_count" = "Non-Motorized Vehicles that are Not Bikes (e.g., carts)")
# 2. If list multiple segments in one video, choose the first one --------------
road_data$segment_id <- road_data$segment_id %>%
str_replace_all("_", ",") %>%
str_replace_all(",.*","")
# 3. Deal with NAs -------------------------------------------------------------
# If no segment ID, give sement 1. These are cases where the video indicated no
# segment ID
road_data$segment_id[is.na(road_data$segment_id)] <- 1
# If no side of road, give side "a"
road_data$road_side_ab[is.na(road_data$road_side_ab)] <- "a"
# 3. Collapse Data to segment-side ---------------------------------------------
# Occasionally multiple entries for different parts of video. For each segment-side,
# take (1) total counts, (2) total minutes counted -- so can then get per minute stats
road_data <- road_data[!(road_data$road_side_ab %in% "a,b"),]
road_data$hotspot_segment_side <- paste0(road_data$hotspot_id,"_", road_data$segment_id,"_", road_data$road_side_ab)
road_data$hotspot_segment_side
shiny::runApp('Documents/Github/Kenya-Police-Dashboard')
runApp('Documents/Github/Kenya-Police-Dashboard')
runApp('Documents/Github/Kenya-Police-Dashboard')
runApp('Documents/Github/Kenya-Police-Dashboard')
shiny::runApp('Documents/Github/Kenya-Police-Dashboard')
source('~/Documents/Github/Kenya-Police-Dashboard/installer.R', echo=TRUE)
source('~/Documents/Github/Kenya-Police-Dashboard/installer.R', echo=TRUE)
source('~/Documents/Github/Kenya-Police-Dashboard/installer.R', echo=TRUE)
shiny::runApp('Documents/Github/Kenya-Police-Dashboard')
runApp('Documents/Github/Kenya-Police-Dashboard')
source('~/Documents/Github/Kenya-Police-Dashboard/installer.R', echo=TRUE)
source('~/Documents/Github/Kenya-Police-Dashboard/installer.R', echo=TRUE)
source('~/Documents/Github/Kenya-Police-Dashboard/installer.R', echo=TRUE)
getwd()
'/Users/robmarty/Documents/Github/Ethiopia-Corridors-IE/Code/general_functions/GOSTNets/GOSTNets'
setwd('/Users/robmarty/Documents/Github/Ethiopia-Corridors-IE/Code/general_functions/GOSTNets/GOSTNets'
)
# Create Points at DMSPOLS Level
# Creates a blank (1) point dataset and (2) polygon dataset of grids at the DMSP-OLS
# level (ie, 1x1km grid). These datasets contain a unique ID and spatial information.
# The points file is saved as a dataframe with lat/lon while the poylgon is saved
# as a spatial features object.
# The script also generates a dataset that includes a panel of DMSP-OLS data. It
# is done in this script as the process for preparing the above files makes
# creating this one quick
set.seed(42)
PROPORTION_SAMPLE <- 0.05
# Load Data --------------------------------------------------------------------
dmspols <- raster(file.path(rawdata_file_path, "Nighttime Lights", "DMSP_OLS","Stacked", "eth_dmspols_allyears.tif"),1)
eth_adm3 <- readRDS(file.path(rawdata_file_path, "GADM", "gadm36_ETH_3_sp.rds"))
# Determine Pixels to Keep Based on Location -----------------------------------
# Creates a vector of cells_to_keep that is TRUE when we should keep cells. Don't
# directly restrict cells yet as using raster format. Subsetting comes in later
# step after polygonizing and making point file.
#### Restrict to Ethiopia Based on GEE
# Only keep cells without value for NTL. Removes area not in Ethiopia according to GEE;
# this is because GEE only exported NTL for areas in the country.
dmspols_df <- dmspols[] %>% as.data.frame
cells_to_keep <- !is.na(dmspols_df$.)
#### Restrict to Ethiopia Based on GADM
# Only keep cells within boundary of Ethiopia according to GADM
dmspols_coords <- coordinates(dmspols) %>%
as.data.frame %>%
dplyr::rename(long = x) %>%
dplyr::rename(lat = y)
coordinates(dmspols_coords) <- ~long+lat
crs(dmspols_coords) <- CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
points_OVER_gadm <- sp::over(dmspols_coords, eth_adm3)
cells_to_keep <- cells_to_keep & !is.na(points_OVER_gadm$NAME_0)
# Keep Random Sample of Cells --------------------------------------------------
# We restrict the sample to an X percent sample. We further refine the cells_to_keep
# vector.
cells_to_keep[cells_to_keep %in% TRUE] <- sample(x = c(TRUE, FALSE),
size = length(cells_to_keep[cells_to_keep %in% TRUE]),
replace = T,
prob = c(PROPORTION_SAMPLE, 1-PROPORTION_SAMPLE))
# Individual Points ------------------------------------------------------------
dmspols_coords <- coordinates(dmspols) %>%
as.data.frame %>%
dplyr::rename(long = x) %>%
dplyr::rename(lat = y)
dmspols_coords <- dmspols_coords[cells_to_keep,]
dmspols_coords$cell_id <- 1:nrow(dmspols_coords)
saveRDS(dmspols_coords, file.path(finaldata_file_path, DATASET_TYPE, "individual_datasets","points.Rds"))
write_csv(dmspols_coords, file.path(finaldata_file_path, DATASET_TYPE, "individual_datasets","points.csv"))
# Ethiopia IE
# Master R Script
# Filepaths --------------------------------------------------------------------
if(Sys.info()[["user"]] == "WB554990") project_file_path <- "C:/Users/wb521633/Dropbox/World Bank/IEs/Ethiopia IE - Merge Budget Data With Shapefile"
if(Sys.info()[["user"]] == "WB521633") project_file_path <- "C:/Users/wb521633/Dropbox/World Bank/IEs/Ethiopia IE"
if(Sys.info()[["user"]] == "robmarty") project_file_path <- "~/Dropbox/World Bank/IEs/Ethiopia IE"
rawdata_file_path <- file.path(project_file_path, "Data", "RawData")
outputs_for_grid <- file.path(project_file_path, "Data", "IntermediateData", "Outputs for Grid")
finaldata_file_path <- file.path(project_file_path, "Data", "FinalData")
figures_file_path <- file.path(project_file_path,"Outputs", "Results", "Figures")
tables_file_path <- file.path(project_file_path,"Outputs", "Results", "Tables")
# Parameters -------------------------------------------------------------------
DATASET_TYPE <- "dmspols_grid_dataset_randomsample"
# Parameters for Grid Analysis
CHUNK_SIZE_DIST_ROADS <- 1250
MCCORS_DIST_ROADS <- 1
TYPE <- c("DMSPOLS") # globcover, DMSPOLS
UTM_ETH <- '+init=epsg:20138'
DIST_THRESH <- 2
# Packages ---------------------------------------------------------------------
library(rgdal)
library(raster)
library(velox)
library(dplyr)
library(rgeos)
library(parallel)
library(pbmcapply)
library(data.table)
library(haven)
library(spex)
library(sf)
library(tidyr)
library(lfe)
library(reshape)
library(dplyr)
library(ggplot2)
library(data.table)
library(coefplot)
library(stringr)
library(doBy)
library(stargazer)
library(scales)
library(rasterVis)
library(ggpubr)
source("https://raw.githubusercontent.com/ramarty/fast-functions/master/R/functions_in_chunks.R")
# Create Points at DMSPOLS Level
# Creates a blank (1) point dataset and (2) polygon dataset of grids at the DMSP-OLS
# level (ie, 1x1km grid). These datasets contain a unique ID and spatial information.
# The points file is saved as a dataframe with lat/lon while the poylgon is saved
# as a spatial features object.
# The script also generates a dataset that includes a panel of DMSP-OLS data. It
# is done in this script as the process for preparing the above files makes
# creating this one quick
set.seed(42)
PROPORTION_SAMPLE <- 0.05
# Load Data --------------------------------------------------------------------
dmspols <- raster(file.path(rawdata_file_path, "Nighttime Lights", "DMSP_OLS","Stacked", "eth_dmspols_allyears.tif"),1)
eth_adm3 <- readRDS(file.path(rawdata_file_path, "GADM", "gadm36_ETH_3_sp.rds"))
# Determine Pixels to Keep Based on Location -----------------------------------
# Creates a vector of cells_to_keep that is TRUE when we should keep cells. Don't
# directly restrict cells yet as using raster format. Subsetting comes in later
# step after polygonizing and making point file.
#### Restrict to Ethiopia Based on GEE
# Only keep cells without value for NTL. Removes area not in Ethiopia according to GEE;
# this is because GEE only exported NTL for areas in the country.
dmspols_df <- dmspols[] %>% as.data.frame
cells_to_keep <- !is.na(dmspols_df$.)
#### Restrict to Ethiopia Based on GADM
# Only keep cells within boundary of Ethiopia according to GADM
dmspols_coords <- coordinates(dmspols) %>%
as.data.frame %>%
dplyr::rename(long = x) %>%
dplyr::rename(lat = y)
coordinates(dmspols_coords) <- ~long+lat
crs(dmspols_coords) <- CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
points_OVER_gadm <- sp::over(dmspols_coords, eth_adm3)
cells_to_keep <- cells_to_keep & !is.na(points_OVER_gadm$NAME_0)
# Keep Random Sample of Cells --------------------------------------------------
# We restrict the sample to an X percent sample. We further refine the cells_to_keep
# vector.
cells_to_keep[cells_to_keep %in% TRUE] <- sample(x = c(TRUE, FALSE),
size = length(cells_to_keep[cells_to_keep %in% TRUE]),
replace = T,
prob = c(PROPORTION_SAMPLE, 1-PROPORTION_SAMPLE))
# Individual Points ------------------------------------------------------------
dmspols_coords <- coordinates(dmspols) %>%
as.data.frame %>%
dplyr::rename(long = x) %>%
dplyr::rename(lat = y)
dmspols_coords <- dmspols_coords[cells_to_keep,]
dmspols_coords$cell_id <- 1:nrow(dmspols_coords)
saveRDS(dmspols_coords, file.path(finaldata_file_path, DATASET_TYPE, "individual_datasets","points.Rds"))
write_csv(dmspols_coords, file.path(finaldata_file_path, DATASET_TYPE, "individual_datasets","points.csv"))
library(readr)
write_csv(dmspols_coords, file.path(finaldata_file_path, DATASET_TYPE, "individual_datasets","points.csv"))
